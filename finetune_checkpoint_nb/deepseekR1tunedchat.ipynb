{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a687f64b",
   "metadata": {},
   "source": [
    "Hii SO here its further finetuning from the checkpoint of first tuning of base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421af20",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().system('pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git --quiet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c916e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().system('pip install trl transformers peft accelerate datasets bitsandbytes --quiet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea0051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().system('pip install -U bitsandbytes --quiet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305e1a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from transformers import TrainingArguments\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from trl import SFTTrainer\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported, to_sharegpt, standardize_sharegpt, apply_chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bda757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep -E 'unsloth|bitsandbytes|torch'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a0579c",
   "metadata": {},
   "source": [
    "bitsandbytes may occur error , depends on your environment, if works then ignore below first cell.\n",
    "If error again then - pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dbe523",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall bitsandbytes -y && pip install bitsandbytes --prefer-binary --no-build-isolation --verbose --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e20a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name     = \"Aeshp/deepseekR1tunedchat\",  #this is tuning again on top of base model\n",
    "    max_seq_length = 2048,\n",
    "    dtype          = None,\n",
    "    load_in_4bit    = True,\n",
    "    device_map     = \"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e112e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r                  = 4,\n",
    "    target_modules     = [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],\n",
    "    lora_alpha         = 16,\n",
    "    lora_dropout       = 0,\n",
    "    bias               = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state       = 42,\n",
    "    use_rslora         = False,\n",
    "    loftq_config       = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acab8bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# define the data files and paths\n",
    "data_files = {\n",
    "    \"train\": \"/content/train.jsonl\",\n",
    "    \"eval\":  \"/content/test.jsonl\",\n",
    "}\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "print(\"Columns:\", dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b5c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05513005",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['eval'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b7b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train        = 500      #adjust according to yourself # total number of training examples as here i am using 500 examples\n",
    "batch_size     = 1\n",
    "grad_accum     = 8\n",
    "num_epochs     = 4\n",
    "steps_per_epoch= math.ceil(N_train / (batch_size * grad_accum))\n",
    "total_steps    = num_epochs * steps_per_epoch\n",
    "warmup_steps   = 10\n",
    "learning_rate  = 2e-5\n",
    "\n",
    "print(f\"N_train: {N_train}\")\n",
    "print(f\"batch_size: {batch_size}\")\n",
    "print(f\"grad_accum: {grad_accum}\")\n",
    "print(f\"num_epochs: {num_epochs}\")\n",
    "print(f\"steps_per_epoch: {steps_per_epoch}\")\n",
    "print(f\"total_steps: {total_steps}\")\n",
    "print(f\"warmup_steps: {warmup_steps}\")\n",
    "print(f\"learning_rate: {learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d6648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboard accelerate matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.integrations import TensorBoardCallback\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db013b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_name_for_log = \"Aeshp/deepseekR1tunedchat\" \n",
    "\n",
    "output_dir = \"outputs\"\n",
    "tensorboard_log_dir = os.path.join(output_dir, \"runs\", f\"{timestamp}_{model_name_for_log}\")\n",
    "checkpoint_dir = os.path.join(output_dir, \"checkpoints\")\n",
    "\n",
    "\n",
    "os.makedirs(tensorboard_log_dir, exist_ok=True)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "print(f\"TensorBoard log directory created: {tensorboard_log_dir}\")\n",
    "print(f\"Checkpoint directory created: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11318cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir {tensorboard_log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dd724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup SFTTrainer\n",
    "# setup TensorBoard logging\n",
    "log_dir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoardCallback(log_dir)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    train_dataset = dataset[\"train\"],\n",
    "    eval_dataset = dataset[\"eval\"],\n",
    "    args = TrainingArguments(\n",
    "        output_dir = \"outputs\",\n",
    "        per_device_train_batch_size = batch_size,\n",
    "        gradient_accumulation_steps = grad_accum,\n",
    "        warmup_steps = warmup_steps,\n",
    "        num_train_epochs = num_epochs,\n",
    "        learning_rate = learning_rate,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1, # Log every step\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 42,\n",
    "        save_strategy = \"epoch\",       # save checkpoint at the end of each epoch\n",
    "    ),\n",
    "    #callbacks=[tensorboard_callback], # Add TensorBoard callback #Enable this line to use TensorBoard callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c5a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()  #train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04650754",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4bfc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#push only weights to the huggingface model repo.\n",
    "\n",
    "!pip install huggingface_hub -q\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392b26e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"your_username/your_model_name\" with your Hugging Face username and model repository name\n",
    "repo_name = \"Your model repo\" #add\n",
    "\n",
    "# Push the model and tokenizer to the Hugging Face Hub\n",
    "model.push_to_hub(repo_name)\n",
    "tokenizer.push_to_hub(repo_name)\n",
    "\n",
    "print(f\"Model and tokenizer pushed to https://huggingface.co/{repo_name}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
